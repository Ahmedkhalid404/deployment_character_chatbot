{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth\n",
    "else:\n",
    "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n",
    "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
    "    !pip install --no-deps unsloth"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install -q fastapi uvicorn pyngrok nest_asyncio langchain transformers faiss-cpu",
   "id": "cc0685c45f3daf2b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install -U langchain-community",
   "id": "d358231247a8b2c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install -U bitsandbytes",
   "id": "2ac80d361dfa586c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install -U langchain-openai",
   "id": "26c18ebda4da60e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import json\n",
    "import torch\n",
    "import nest_asyncio\n",
    "import threading\n",
    "import logging\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional, List, Dict\n",
    "from pyngrok import ngrok\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "import zipfile"
   ],
   "id": "f8bf06ec18b11a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "app = FastAPI()\n",
    "app.add_middleware(CORSMiddleware, allow_origins=[\"*\"], allow_credentials=True, allow_methods=[\"*\"], allow_headers=[\"*\"])\n",
    "\n",
    "class ChatRequest(BaseModel):\n",
    "    input: str\n",
    "    messages: Optional[List[Dict[str, str]]] = None"
   ],
   "id": "c75d61ad688d29eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "zip_path = \"/content/saved_data.zip\"\n",
    "extract_path = \"/content/saved_data\"\n",
    "\n",
    "try:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_path)\n",
    "    print(\"Extraction successful!\")\n",
    "except zipfile.BadZipFile:\n",
    "    print(\"Bad zip file or corrupted.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ],
   "id": "85a3fd77dbae0358"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "vectorstore_path = \"/content/saved_data/faiss_index\"\n",
    "store_path = \"/content/saved_data/document_store.json\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\",\n",
    "    openai_api_key=\"****\"\n",
    ")\n",
    "\n",
    "vectorstore = FAISS.load_local(vectorstore_path, embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "store = InMemoryStore()\n",
    "with open(store_path, \"r\") as f:\n",
    "    store_data = json.load(f)\n",
    "for key, doc_dict in store_data.items():\n",
    "    doc = Document(page_content=doc_dict[\"page_content\"], metadata=doc_dict[\"metadata\"])\n",
    "    store.mset([(key, doc)])\n",
    "\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=400)\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=None,\n",
    "    search_kwargs={\"k\": 3}\n",
    ")\n"
   ],
   "id": "b1b9278c7eb3a3f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import AutoTokenizer\n",
    "from unsloth import FastLanguageModel\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "max_seq_length = 16384\n",
    "dtype = None\n",
    "load_in_4bit = True\n",
    "\n",
    "adapter_map = {\n",
    "    \"sherlock\": \"ahmedkhaled74/sherlock_lora_v4\",\n",
    "    \"moriarity\": \"ahmedkhaled74/moriarity_lora\",\n",
    "}\n",
    "\n",
    "local_adapter_paths = {\n",
    "    name: snapshot_download(repo_id=repo_id)\n",
    "    for name, repo_id in adapter_map.items()\n",
    "}\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = local_adapter_paths[\"sherlock\"],\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")\n",
    "model = FastLanguageModel.for_inference(model)\n",
    "\n",
    "def change_adapter(character_name: str):\n",
    "    character_name = character_name.lower()\n",
    "\n",
    "    if character_name not in local_adapter_paths:\n",
    "        raise ValueError(f\"Unknown character_name: {character_name}. Available: {list(local_adapter_paths.keys())}\")\n",
    "\n",
    "    new_adapter_path = local_adapter_paths[character_name]\n",
    "\n",
    "    model.load_adapter(new_adapter_path, adapter_name=\"default\", replace=True)\n",
    "    print(f\"Switched to {character_name.title()} adapter.\")\n",
    "\n",
    "change_adapter(\"sherlock\")"
   ],
   "id": "df8b4568229de42"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "change_adapter(\"sherlock\")",
   "id": "aac7a90cf34915b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_template(question,possible_answers):\n",
    "  template = \"\"\"Use the context you have and answer based on it. Use the context to answer any question about events while impersonating your character.\n",
    "    Scenes:\n",
    "    {possible_answers}\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "  return template.format(possible_answers=possible_answers, question=question)\n"
   ],
   "id": "cfd33c9468adb950"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import TextStreamer\n",
    "def character_answer(question: str, messages: Optional[List[Dict[str, str]]] = None) -> str:\n",
    "    relevant_docs = retriever.get_relevant_documents(question)\n",
    "    possible_answers = \"\"\n",
    "    for i, doc in enumerate(relevant_docs[:3]):\n",
    "        possible_answers += f\"Answer {i + 1}:\\n{doc.page_content}\\n\"\n",
    "\n",
    "    context_prompt = create_template(possible_answers=possible_answers, question=question)\n",
    "\n",
    "    full_prompt = []\n",
    "\n",
    "    if messages:\n",
    "        full_prompt.extend(messages)\n",
    "\n",
    "    full_prompt.append({\"role\": \"user\", \"content\": context_prompt})\n",
    "\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        full_prompt,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs,\n",
    "        max_new_tokens=2056,\n",
    "        use_cache=True\n",
    "    )\n",
    "\n",
    "    input_length = inputs.shape[1]\n",
    "\n",
    "    decoded = tokenizer.decode(outputs[0][input_length:], skip_special_tokens=True)\n",
    "\n",
    "    return decoded.strip()\n",
    "\n"
   ],
   "id": "547426548811b68f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import uvicorn\n",
    "from fastapi import Request\n",
    "\n",
    "class AdapterRequest(BaseModel):\n",
    "    character_name: str\n",
    "\n",
    "@app.post(\"/change_adapter\")\n",
    "def change_adapter(request: AdapterRequest):\n",
    "    character_name = request.character_name.lower()\n",
    "\n",
    "    if character_name not in local_adapter_paths:\n",
    "        raise HTTPException(\n",
    "            status_code=400,\n",
    "            detail=f\"Unknown character_name '{character_name}'. Available: {list(local_adapter_paths.keys())}\"\n",
    "        )\n",
    "\n",
    "    new_adapter_path = local_adapter_paths[character_name]\n",
    "\n",
    "    try:\n",
    "        model.load_adapter(new_adapter_path, adapter_name=\"default\", replace=True)\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Failed to load adapter: {str(e)}\")\n",
    "\n",
    "    return {\"message\": f\"Switched to {character_name.title()} adapter.\"}\n",
    "\n",
    "@app.post(\"/chat/character\")\n",
    "async def chat_character(request: Request):\n",
    "    try:\n",
    "        body = await request.json()\n",
    "        question = body.get(\"input\", \"\").strip()\n",
    "        if not question:\n",
    "            raise HTTPException(status_code=400, detail=\"Missing 'input' field\")\n",
    "\n",
    "        messages = body.get(\"messages\", [])\n",
    "\n",
    "        logger.info(f\"Received question: {question}\")\n",
    "        answer = character_answer(question, messages)\n",
    "\n",
    "        return {\"response\": answer}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in /chat/character: {str(e)}\")\n",
    "        return {\"response\": f\"Error: {str(e)}\", \"error\": True}\n",
    "\n",
    "def run_server():\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8001)\n",
    "\n",
    "server_thread = threading.Thread(target=run_server)\n",
    "server_thread.start()\n",
    "\n",
    "ngrok.set_auth_token(\"****\")\n",
    "public_url = ngrok.connect(8001)\n",
    "print(f\"ðŸš€ API Base: {public_url}\")\n",
    "print(f\"ðŸ§  Sherlock endpoint: {public_url}/chat/character\")"
   ],
   "id": "4e45d41a0c3e8a71"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "question = \"introduce yourself\"\n",
    "print(character_answer(question))"
   ],
   "id": "f46d9f36b19fb6ef"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
